{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models\n",
    "import data_preprocess\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "from metrics import CosineSimilarity,BLEUScore,ROUGEScore_custom,METEORScore\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "with open('config.json','r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_evals = 5\n",
    "from_lang = 'fra'\n",
    "to_lang = 'eng'\n",
    "attn = 'True'\n",
    "rnn = 'gru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self,config_dict,device) -> None:\n",
    "        self.config_dict = config_dict\n",
    "        self.hidden_size = config_dict['hidden_size']\n",
    "        self.batch_size = config_dict['batch_size']\n",
    "        self.from_lang_str = config_dict['from_lang']\n",
    "        self.max_length = config_dict['max_sentence_length']\n",
    "        self.attention_flag = config_dict[\"use_attention\"]\n",
    "\n",
    "        self.use_pkl_data = config_dict['use_pkl_data']\n",
    "\n",
    "        self.indx_sent_func = data_preprocess.indexesFromSentence\n",
    "        self.optimizer = None\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.epoch_count = config_dict['epoch_count']\n",
    "        self.learning_rate = config_dict['learning_rate']\n",
    "\n",
    "    \n",
    "        with open('{}_to_{}.pkl'.format(from_lang,to_lang), 'rb') as f:\n",
    "            loads = pickle.load(f)\n",
    "\n",
    "        \n",
    "        self.in_lang = loads['input_lang'] #Input language model\n",
    "        self.out_lang = loads['output_lang'] #Output language model\n",
    "        self.in_ids = loads['test_input_ids'] #Input language as integer vectors\n",
    "        self.tgt_ids = loads['test_target_ids'] #Target language as integer vectors\n",
    "        self.pairs = loads['test_pairs'] #String pairs of input and target language\n",
    "        self.SOS_token = loads['SOS_token']\n",
    "        self.EOS_token = loads['EOS_token']\n",
    "\n",
    "        print(\"Evaluating translation from {} to {}\".format(self.in_lang.name,self.out_lang.name))\n",
    "        \n",
    "        encoder_dict = {\n",
    "            'input_size':self.in_lang.n_words,\n",
    "            'hidden_size':self.hidden_size,\n",
    "            'recurrent_arch': config_dict['rnn_type'],\n",
    "            'dropout_p':0.1\n",
    "        }\n",
    "\n",
    "        decoder_dict = {\n",
    "            'hidden_size':self.hidden_size,\n",
    "            'output_size':self.out_lang.n_words,\n",
    "            'recurrent_arch':config_dict['rnn_type'],\n",
    "            'max_len':self.max_length,\n",
    "            'arg_device':self.device\n",
    "        }\n",
    "\n",
    "        self.attention_flag = True if attn == 'True' else False\n",
    "\n",
    "        if self.attention_flag:\n",
    "            self.encoder = models.CustomEncoderRNN(encoder_dict).to(self.device)\n",
    "            self.decoder = models.CustomAttnDecoderRNN(decoder_dict).to(self.device)\n",
    "        else:\n",
    "            self.encoder = models.CustomEncoderRNN(encoder_dict).to(self.device)\n",
    "            self.decoder = models.CustomDecoderRNN(decoder_dict).to(self.device)\n",
    "\n",
    "        base_str = f\"{from_lang}_to_{to_lang}_attn_{attn}_rnn_{rnn}\"\n",
    "\n",
    "        self.encoder_weights = torch.load(f'{base_str}_encoder_best.pth')\n",
    "        self.decoder_weights = torch.load(f'{base_str}_decoder_best.pth')\n",
    "\n",
    "        self.encoder.load_state_dict(self.encoder_weights)\n",
    "        self.decoder.load_state_dict(self.decoder_weights)\n",
    "\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        self.tfs = data_preprocess.tensorFromSentence\n",
    "\n",
    "        \n",
    "    def evaluate(self,encoder, decoder, sentence, input_lang, output_lang):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_tensor = torch.IntTensor(self.tfs(input_lang, sentence,self.EOS_token)).to(self.device).view(1, -1)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "            decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden,None,self.SOS_token)\n",
    "            _, topi = decoder_outputs.topk(1)\n",
    "            \n",
    "            decoded_ids = topi.squeeze()\n",
    "\n",
    "            decoded_words = []\n",
    "            for idx in decoded_ids:\n",
    "                if idx.item() == self.EOS_token:\n",
    "                    break\n",
    "                decoded_words.append(output_lang.index2word[idx.item()])\n",
    "        return decoded_words, decoder_attn\n",
    "\n",
    "    def evaluateRandomly(self,encoder, decoder, n=1):\n",
    "        for i in range(num_evals):\n",
    "            pair = random.choice(self.pairs)\n",
    "            print('Input >', pair[0])\n",
    "            print('Expected =', pair[1])\n",
    "            output_words, _ = self.evaluate(encoder, decoder, pair[0], self.in_lang, self.out_lang)\n",
    "            output_sentence = ' '.join(output_words)\n",
    "            print('Got <', output_sentence)\n",
    "            print('\\n')\n",
    "            os = [output_sentence]\n",
    "            ref = [pair[1]]\n",
    "            cs = CosineSimilarity(1).evaluate(ref,os)\n",
    "            bs = BLEUScore(1).evaluate(ref,os)\n",
    "            ms = METEORScore(1).evaluate(ref,os)\n",
    "            rs = ROUGEScore_custom(1).evaluate(ref,os)\n",
    "            cosine_score = cs[0]\n",
    "            bleu_score = bs[0]\n",
    "            meteor_score = ms[0]\n",
    "            rouge_score = rs[0]\n",
    "\n",
    "    def run(self):\n",
    "        self.evaluateRandomly(self.encoder, self.decoder)\n",
    "\n",
    "    def web_eval(self,phrase=None,random=None):\n",
    "        if random:\n",
    "            pair = choice(self.pairs)\n",
    "            phrase = pair[0]\n",
    "            expected = pair[1]\n",
    "            output_words, _ = self.evaluate(self.encoder, self.decoder, phrase, self.in_lang, self.out_lang)\n",
    "            output_sentence = ' '.join(output_words)\n",
    "\n",
    "\n",
    "            return phrase,expected,output_sentence\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating translation from fra to eng\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(config,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input > il y a quelques heures que je lis ca .\n",
      "Expected = i've been reading this for a few hours .\n",
      "Neural < this evening hours reading that .\n"
     ]
    }
   ],
   "source": [
    "phrase,expected,output_sentence = evaluator.web_eval(random=True)\n",
    "print('Input >', phrase)\n",
    "print('Expected =', expected)\n",
    "print('Neural <', output_sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
